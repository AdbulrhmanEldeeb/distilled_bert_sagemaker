{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Setup the SageMaker session\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "# S3 bucket for storing training data and model artifacts\n",
    "bucket = session.default_bucket()\n",
    "prefix = 'distilbert-fine-tuning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a dataset prepared in a format compatible with the Hugging Face transformers library\n",
    "# For sequence classification (e.g., sentiment analysis)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('your_dataset.csv')  # Replace with your actual data loading\n",
    "\n",
    "# Split the dataset\n",
    "train_df, eval_df = train_test_split(df, test_size=0.1)\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Function to tokenize and format data\n",
    "def tokenize_data(texts, labels):\n",
    "    encodings = tokenizer(texts.tolist(), truncation=True, padding=True, max_length=128)\n",
    "    dataset = {\n",
    "        'input_ids': encodings['input_ids'],\n",
    "        'attention_mask': encodings['attention_mask'],\n",
    "        'labels': labels.tolist()\n",
    "    }\n",
    "    return dataset\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = tokenize_data(train_df['text'], train_df['label'])\n",
    "eval_dataset = tokenize_data(eval_df['text'], eval_df['label'])\n",
    "\n",
    "# Convert to format expected by SageMaker\n",
    "import json\n",
    "import os\n",
    "\n",
    "def write_to_jsonl(dataset, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for i in range(len(dataset['input_ids'])):\n",
    "            item = {\n",
    "                'input_ids': dataset['input_ids'][i],\n",
    "                'attention_mask': dataset['attention_mask'][i],\n",
    "                'labels': dataset['labels'][i]\n",
    "            }\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "# Create local files\n",
    "write_to_jsonl(train_dataset, 'train.jsonl')\n",
    "write_to_jsonl(eval_dataset, 'eval.jsonl')\n",
    "\n",
    "# Upload to S3\n",
    "train_s3 = session.upload_data('train.jsonl', bucket=bucket, key_prefix=f\"{prefix}/data\")\n",
    "eval_s3 = session.upload_data('eval.jsonl', bucket=bucket, key_prefix=f\"{prefix}/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# Hyperparameters for fine-tuning\n",
    "hyperparameters = {\n",
    "    'epochs': 3,\n",
    "    'train_batch_size': 16,\n",
    "    'eval_batch_size': 16,\n",
    "    'learning_rate': 5e-5,\n",
    "    'warmup_steps': 500,\n",
    "    'model_name': 'distilbert-base-uncased',\n",
    "    'output_dir': '/opt/ml/model'\n",
    "}\n",
    "\n",
    "# Create Hugging Face estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point='train.py',  # Your training script\n",
    "    source_dir='./scripts',  # Directory containing your training scripts\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p3.2xlarge',  # Consider your budget and requirements\n",
    "    transformers_version='4.26.0',  # Specify the transformers version\n",
    "    pytorch_version='1.13.1',       # Specify the PyTorch version\n",
    "    py_version='py39',              # Python version\n",
    "    hyperparameters=hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training job\n",
    "huggingface_estimator.fit({\n",
    "    'training': train_s3,\n",
    "    'eval': eval_s3\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "# Create the Hugging Face Model\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    model_data=huggingface_estimator.model_data,  # S3 path to your model.tar.gz\n",
    "    role=role,\n",
    "    transformers_version=\"4.26.0\",\n",
    "    pytorch_version=\"1.13.1\",\n",
    "    py_version=\"py39\",\n",
    "    entry_point=\"inference.py\"  # Your inference script\n",
    ")\n",
    "\n",
    "# Deploy the model\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\"  # Choose an appropriate instance type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with example data\n",
    "sample_data = {\n",
    "    'texts': [\n",
    "        \"I absolutely loved the movie, the acting was superb!\",\n",
    "        \"The service at the restaurant was terrible and the food was cold.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Get predictions\n",
    "response = predictor.predict(sample_data)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
